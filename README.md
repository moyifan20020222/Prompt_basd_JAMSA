# Prompt_basd_JAMSA

本部分先记录使用 以GMP为基础的代码上，增加Prompt Tuning 以提升模型在 MATE MASC JAMSA任务上的性能， 目前的方法已经较之原文有了部分性能的提升

不足：
原始论文的数据集的选取过于偏差，导致MATE任务的性能受到较大限制，进而影响了JMASA任务的性能， 目前需要在MASAD数据集上 验证 数据集中的Aspect的多样性是否会影响本篇提出方法的性能。

为此我们需要使用Blip模型重新处理Twitter15和17的数据集 以及 MASAD数据集，以保证数据格式和GMP代码的处理格式一致。

之后在twiiter数据集上，验证样本数量的阈值，检验我们的方法在何种程度下的 少样本会出现过拟合。

而如果我们的方法确实能提升MATE性能，则考虑将MASAD数据集的格式 往持续学习方面修改任务定义。


-----
4.25
增加关于图像与文本相关度的部分，通过BLIP-ITM标注，让字幕信息和文本信息做交叉注意力融合后学习相关度的计算，对于无法提取字幕的部分，用一个特定值表示。看看效果能提升吗

--------
4.27
把情绪Prompt和Aspect各自的总Prompt生成中使用的融合部分同样扩展到 每一个具体Aspect的情绪Prompt的构建当中，验证提升效果
